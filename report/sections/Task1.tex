\section{Dataset Characterization and Preprocessing}\label{sec:task1}
\subsection{Dataset Characterization}
\paragraph{Dataset exploration}
The training dataset (extracted from \texttt{train.json}) contains 18831 rows, while the test dataset (from \texttt{test.json}) 5826. Both datasets are characterized by 43 columns, of which 41 features and 2 labels. There are three main types of features: basic ones (connection duration, protocol type, service, status flags, \dots),  content ones (about the packets' payload) and traffic ones (summarizing network level statistics). The last two columns are the \texttt{label}, indicating the attack type, and \texttt{binary\_label}, telling whether the flow is flagged as anomalous or not.

\paragraph{Categorical and numerical features} Among the 41 features, only 3 are categorical: \texttt{protocol\_type}, \texttt{service}, \texttt{flag}. Hence, there are 38 numerical features: three of them have always value 0 (\texttt{urgent}, \texttt{num\_outbouhnd\_cmds}, \texttt{is\_host\_login}) and five are binary (\texttt{land}, \texttt{logged\_in}, \texttt{root\_shell}, \texttt{num\_shell}, \texttt{is\_guest\_login}).

\paragraph{Label distribution} \Cref{tab:task1_label_distribution} shows the distribution of the labels and binary labels in the training and test dataset. In the training dataset, the majority of the samples is identified as benign. The \SI{28.6}{\percent} of samples is malign, and they are split among three different attacks: DoS (\SI{15.5}{\percent}), Probe (\SI{12.2}{\percent}) and R2L (\SI{1.0}{\percent}). In the test dataset, instead, \SI{63.0}{\percent} of samples are anomalies. Two types of attacks are present: DoS (\SI{44.2}{\percent}) and Probe (\SI{18.8}{\percent}).

\begin{table}
\small
\centering
\caption{Attack label distribution in the training and test dataset. In total, 5383 (\SI{28.6}{\percent}) samples are anomalies in the training dataset, while 3674 (\SI{63.0}{\percent}) in the test one.}
\label{tab:task1_label_distribution}
\begin{tabular}{cccccc}
\toprule
{Attack Label} & {Count$_{train}$} & {Percentage$_{train}$} & {Count$_{test}$} & {Percentage$_{test}$} & {Binary label} \\
\midrule
Normal & 13448 & \SI{71.4}{\percent} & 2152 & \SI{36.9}{\percent} & Normal (0) \\
DoS & 2913 & \SI{15.5}{\percent} & 2577 & \SI{44.2}{\percent} & Anomaly (1) \\
Probe & 2289 & \SI{12.2}{\percent} & 1097 & \SI{18.8}{\percent} & Anomaly (1) \\
R2L & 181 & \SI{1.0}{\percent} & 0 & \SI{0.0}{\percent} & Anomaly (1) \\
\bottomrule
\end{tabular}
\end{table}


\subsection{Preprocessing}
First, we split the training dataset in train and validation set, with a ratio of 9:1 respectively. While only required for Task 3, we decided to perform the splitting at the beginning nonetheless to avoid leaking information from data that will later be used for validation (i.e., during pre-processing), and to ensure consistency by always using the same training set in all the following sections. We chose this ratio given the high number of samples in the original set, that ensures we have enough samples also in the validation set while keeping most of the information in the training set. This choice seems sound, since the models in \cref{sec:task3} converge and do not overfit.

Second, we verified whether the train, validation or test sets contained infinite, NaN or duplicated samples: we did not identify any of them. Third, we dropped the columns we have already identified as only containing the value 0 (\texttt{urgent}, \texttt{num\_outbouhnd\_cmds}, \texttt{is\_host\_login}) in all sets, since they do not carry any useful information while increasing the dimensionality. Fourth, since the attack labels are words, we encoded them using the \texttt{LabelEncoder}.

\paragraph{Preprocessing of categorical features} To preprocess categorical features, we identified how many values they can assume and how many samples for each value (on the training set). Then, we defined the allowed list of values based on their frequency and mapped the other ones to \texttt{other}. In particular, \texttt{service} has 15 different values; we kept the six most frequent ones (\texttt{http}, \texttt{private}, \texttt{smtp}, \texttt{domain\_u}, \texttt{other}, \texttt{ftp\_data}, \texttt{ecr\_i}) and we added all the other samples to \texttt{other} (that already existed in the column). \texttt{flag} has 11 different values; we kept the five most frequent ones (\texttt{SF}, \texttt{S0}, \texttt{REJ}, \texttt{RSTR}, \texttt{RSTO}) and we mapped all the others to \texttt{other}. \texttt{protocol\_type} only contains three different values, so we kept all of them. Once we have reduced the number of different values, we applied one hot encoding: at this point, the datasets are characterized by 52 features.

\paragraph{Preprocessing of numerical features} First, we visualized the distribution of values for numerical features: since different features contain outliers (e.g., \texttt{num\_compromized}), we decided to apply standardization (Z-score scaling). The \texttt{StandardScaler} was fit only on the training set to avoid data leakage, with the same transformation applied to validation and test sets.

\subsection{Heatmaps} \Cref{fig:task1_heatmaps} shows the heatmaps representing mean, standard deviation and median of the most discriminative features per attack label. DoS attacks are characterized by high mean and median values for connection counts (\texttt{count}), high errors rates related to handshake failures (\texttt{serror\_rate}, \texttt{srv\_serror\_rate}, \texttt{dst\_host\_serror\_rate}, \texttt{dst\_host\_srv\_serror\_rate}), high wrong fragments (\texttt{wrong\_fragment}) and low service diversity (\texttt{same\_srv\_rate}). These observations are consistent with the attack type: in DoS, attackers flood the target with repeated connection attempts, often resulting in many failed or half-open connections. Probe attacks, instead, scan many hosts or services to gather information. Hence, they use the same source probing for multiple destinations and change frequently destination port and service, leading to a high value of mean and median for \texttt{srv\_diff\_host\_rate} and \texttt{dst\_host\_same\_src\_port\_rate}. Also in this case, the mean error rates are quite high, especially those related to rejected connections (\texttt{rerror\_rate}, \texttt{srv\_rerror\_rate}, \texttt{dst\_host\_srv\_rerror\_rate}, \texttt{dst\_host\_srv\_diff\_host\_rate}, \texttt{dst\_host\_rerror\_rate}), which is consistent with the attack process. However, the medians are lower, indicating that a relatively small number of samples have very high values (as testified also by the high standard deviation). The \texttt{duration} of the connection varies significantly, as suggested by the high standard deviation. R2L attacks focus on gaining access through authentication abuse rather than traffic volume. In fact, \texttt{guest\_is\_login} and \texttt{hot} are characterized by high average: the attackers successfully logged in, but probably with low privileges, so they tried to do ``sensitive'' operations (\texttt{hot}) to attempt to escalate privileges. However, high standard deviations and lower medians indicate that just a limited set of samples have very high values for those feature. \texttt{dst\_host\_same\_src\_port\_rate} is again quite high. Normal flows have balanced values across most features, with few failures and consistent patterns. They are characterized by higher values for \texttt{logged\_in} and \texttt{service\_http}, reflecting normal web usage.

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{img/Task1/task1_heatmaps_combined.png}
	\caption{Heatmaps showing the mean, standard deviation and median of the most discriminative feature per attack label. Lighter colors indicate lower values, while darker colors higher ones.}
	\label{fig:task1_heatmaps}
\end{figure}
